{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Imports and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml #type:ignore # For reading/writing YAML files if needed for data.yaml manipulation\n",
    "from ultralytics import YOLO #type:ignore\n",
    "from IPython.display import display, Image #type:ignore # For displaying results in Jupyter\n",
    "import glob # For finding files like best.pt using patterns\n",
    "import shutil # For file operations like copying\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.5.1+cu121\n",
      "0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-Defined Paths and Configurations - Fill In!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration parameters set.\n",
      "  Dataset Root Path: C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\n",
      "  Dataset YAML Path: C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\\dataset.yaml\n",
      "  Base Pretrained Model: C:\\Users\\weiss\\Desktop\\JT101\\Models\\larvae_best.pt\n",
      "  Project Name: Larvae_fresh_training\n",
      "  Run Name: train_l_Larvae_seg\n"
     ]
    }
   ],
   "source": [
    "# --- User-Defined Paths and Configuration ---\n",
    "# IMPORTANT: User MUST change this path to point to their dataset root directory.\n",
    "# This directory should contain 'images/', 'labels/', and 'data.yaml' as outputted from colab or Roboflow (the unzipped folder).\n",
    "DATASET_ROOT_PATH = r\"C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\" # EXAMPLE, NEEDS CHANGE\n",
    "\n",
    "# Path to the dataset configuration YAML file.\n",
    "DATASET_YAML_PATH = os.path.join(DATASET_ROOT_PATH, 'dataset.yaml')\n",
    "\n",
    "# --- Model Configuration ---\n",
    "# Choose model size: 'n' (nano), 's' (small), 'm' (medium), 'l' (large), 'x' (extra-large)\n",
    "MODEL_SIZE = 'l'\n",
    "# -- Pretrained - use the best current model or base one ---\n",
    "# BASE_PRETRAINED_MODEL_NAME = r\"C:\\Users\\JellyTracker\\Desktop\\JellyFishTrackingPC-main\\Models\\larvae_best.pt\" # current best larvae segmentation model\n",
    "BASE_PRETRAINED_MODEL_NAME = r\"C:\\Users\\weiss\\Desktop\\JT101\\Models\\larvae_best.pt\" # current best larvae segmentation model\n",
    "\n",
    "# If using a pre-trained YOLOv8 model, it should be in the format below, just change the size (n, s, m, l, x).:\n",
    "# this may or may not work, more testing needed\n",
    "# BASE_PRETRAINED_MODEL_NAME = r\"C:\\Users\\JellyTracker\\Desktop\\BaseModels\\yolov8l-seg.pt\" # \"C:\\Users\\weiss\\Desktop\\BaseModels\\yolov8l-seg.pt\"\n",
    "# BASE_PRETRAINED_MODEL_NAME = r\"C:\\Users\\weiss\\Desktop\\BaseModels\\yolov8l-seg.pt\"\n",
    "\n",
    "# --- Training Run Configuration ---\n",
    "# 'project': Top-level directory for saving runs (e.g., 'runs/s\n",
    "# egment/YOLOv8_Custom_Seg_Training/')\n",
    "# 'name': Specific subdirectory for this run (e.g., 'runs/segment/YOLOv8_Custom_Seg_Training/run_yolov8m-seg_custom/')\n",
    "# These determine where weights (best.pt, last.pt) and logs are saved.[12, 13]\n",
    "PROJECT_NAME = 'Larvae_fresh_training' \n",
    "RUN_NAME = f'train_{MODEL_SIZE}_Larvae_seg' # A descriptive name for the training run\n",
    "\n",
    "# --- Incremental Training: Path to find previous best.pt ---\n",
    "# Ultralytics saves runs in: runs/<task>/<project_name>/<run_name>/\n",
    "# The <run_name> might be appended with a number if it's not unique (e.g., run_name2, run_name3)\n",
    "# This logic will try to find the latest run matching the RUN_NAME pattern.\n",
    "# The path to the actual 'best.pt' will be determined programmatically later.\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "EPOCHS = 150  # Number of training epochs - normal 150\n",
    "IMAGE_SIZE = 640 # Target image size for training (e.g., 640 pixels) [2, 8, 13]\n",
    "BATCH_SIZE = 8   # Number of images per batch; adjust based on GPU memory.\n",
    "                 # Use -1 for auto-batch to utilize ~60% GPU memory.[12, 13]\n",
    "PATIENCE = 10    # Epochs to wait for improvement before early stopping.[12, 13]\n",
    "DEVICE = '0'     # Computational device: '0' for GPU 0, 'cpu', or None for auto-selection.[12, 13]\n",
    "WORKERS = 4      # Number of worker threads for data loading (per RANK if multi-GPU).[12, 13]\n",
    "\n",
    "# This flag is used by model.train(). If True, it ensures weights are loaded.\n",
    "# If YOLO() loads a specific.pt, pretrained=True in train() uses those.\n",
    "# If YOLO() loads a.yaml, pretrained=True in train() loads default weights for that.yaml.\n",
    "# For our logic of loading either base or custom best.pt, this should be True.\n",
    "PRETRAINED_ARG_FOR_TRAIN = True # [12, 13]\n",
    "\n",
    "# --- Output Directories ---\n",
    "# Base directory where Ultralytics saves training runs\n",
    "ULTRALYTICS_RUNS_DIR = 'runs'\n",
    "SEGMENTATION_TASK_DIR = 'segment' # YOLOv8 saves segmentation tasks under 'segment'\n",
    "\n",
    "print(\"Configuration parameters set.\")\n",
    "print(f\"  Dataset Root Path: {DATASET_ROOT_PATH}\")\n",
    "print(f\"  Dataset YAML Path: {DATASET_YAML_PATH}\")\n",
    "print(f\"  Base Pretrained Model: {BASE_PRETRAINED_MODEL_NAME}\")\n",
    "print(f\"  Project Name: {PROJECT_NAME}\")\n",
    "print(f\"  Run Name: {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying Dataset Accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying Dataset Accessibility ---\n",
      "Attempting to locate data.yaml at: C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\\dataset.yaml\n",
      "Successfully found data.yaml: C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\\dataset.yaml\n",
      "\n",
      "Contents of data.yaml:\n",
      "path: C:/Users/weiss/Downloads/larvae_yolo_dataset/larvae_yolo_dataset\n",
      "train: images\n",
      "val: images\n",
      "names:\n",
      "  0: larvae\n",
      "\n",
      "\n",
      "data.yaml contains all required keys (path, train, val, names).\n",
      "\n",
      "Effective dataset path from data.yaml ('path' field): C:/Users/weiss/Downloads/larvae_yolo_dataset/larvae_yolo_dataset\n",
      "Expected training images directory: C:/Users/weiss/Downloads/larvae_yolo_dataset/larvae_yolo_dataset\\images\n",
      "Expected validation images directory: C:/Users/weiss/Downloads/larvae_yolo_dataset/larvae_yolo_dataset\\images\n",
      "Training images directory found.\n",
      "Validation images directory found.\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Verifying Dataset Accessibility ---\")\n",
    "print(f\"Attempting to locate data.yaml at: {DATASET_YAML_PATH}\")\n",
    "\n",
    "if not os.path.exists(DATASET_ROOT_PATH):\n",
    "    print(f\"ERROR: The DATASET_ROOT_PATH does not exist: {DATASET_ROOT_PATH}\")\n",
    "    print(f\"Please ensure the path is correct and the dataset directory is available.\")\n",
    "elif not os.path.exists(DATASET_YAML_PATH):\n",
    "    print(f\"ERROR: data.yaml not found at the specified path: {DATASET_YAML_PATH}\")\n",
    "    print(f\"Please ensure '{os.path.basename(DATASET_YAML_PATH)}' exists in '{DATASET_ROOT_PATH}'.\")\n",
    "else:\n",
    "    print(f\"Successfully found data.yaml: {DATASET_YAML_PATH}\")\n",
    "    try:\n",
    "        with open(DATASET_YAML_PATH, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        print(\"\\nContents of data.yaml:\")\n",
    "        print(yaml.dump(data_config, indent=2, sort_keys=False))\n",
    "\n",
    "        # Verify essential keys in data.yaml\n",
    "        required_keys = ['path', 'train', 'val', 'names']\n",
    "        missing_keys = [key for key in required_keys if key not in data_config]\n",
    "\n",
    "        if missing_keys:\n",
    "            print(f\"\\nWARNING: data.yaml is missing the following required keys: {', '.join(missing_keys)}\")\n",
    "        else:\n",
    "            print(\"\\ndata.yaml contains all required keys (path, train, val, names).\")\n",
    "\n",
    "            # Further check: ensure the 'path' in data.yaml matches DATASET_ROOT_PATH if it's used for relative sub-paths\n",
    "            # or that paths are resolvable.\n",
    "            # For simplicity, we assume 'train' and 'val' are relative to data_config['path']\n",
    "            # and data_config['path'] is either absolute or correctly relative to the execution context.\n",
    "            \n",
    "            # Construct absolute paths for train/val images based on data.yaml content\n",
    "            # This handles cases where data_config['path'] might be relative itself.\n",
    "            # If data_config['path'] is absolute, os.path.join behaves as expected.\n",
    "            # If data_config['path'] is relative, it's joined with DATASET_ROOT_PATH's directory.\n",
    "            \n",
    "            # Path specified inside data.yaml\n",
    "            yaml_path_field = data_config.get('path', '')\n",
    "            if not os.path.isabs(yaml_path_field):\n",
    "                # If path in YAML is relative, assume it's relative to the YAML file's location (DATASET_ROOT_PATH)\n",
    "                effective_dataset_path_from_yaml = os.path.abspath(os.path.join(DATASET_ROOT_PATH, yaml_path_field))\n",
    "            else:\n",
    "                effective_dataset_path_from_yaml = yaml_path_field\n",
    "\n",
    "            print(f\"\\nEffective dataset path from data.yaml ('path' field): {effective_dataset_path_from_yaml}\")\n",
    "\n",
    "            train_images_path = os.path.join(effective_dataset_path_from_yaml, data_config.get('train', ''))\n",
    "            val_images_path = os.path.join(effective_dataset_path_from_yaml, data_config.get('val', ''))\n",
    "\n",
    "            print(f\"Expected training images directory: {train_images_path}\")\n",
    "            print(f\"Expected validation images directory: {val_images_path}\")\n",
    "\n",
    "            if not os.path.isdir(train_images_path):\n",
    "                print(f\"WARNING: Training images directory not found: {train_images_path}\")\n",
    "            else:\n",
    "                print(f\"Training images directory found.\")\n",
    "            \n",
    "            if not os.path.isdir(val_images_path):\n",
    "                print(f\"WARNING: Validation images directory not found: {val_images_path}\")\n",
    "            else:\n",
    "                print(f\"Validation images directory found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not read or parse data.yaml: {e}\")\n",
    "        data_config = None # Ensure data_config is defined for potential later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Model(train from scratch or use pre-trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Determining Model Weights for Training ---\n",
      "Searching for existing run directories matching pattern: runs\\segment\\Larvae_fresh_training\\train_l_Larvae_seg*\n",
      "Using specified model weights file directly: C:\\Users\\weiss\\Desktop\\JT101\\Models\\larvae_best.pt\n",
      "Decision: Will start training FROM or RESUME using: C:\\Users\\weiss\\Desktop\\JT101\\Models\\larvae_best.pt\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Determining Model Weights for Training ---\")\n",
    "model_weights_to_load = BASE_PRETRAINED_MODEL_NAME  # Default to the base official pretrained model\n",
    "\n",
    "# Construct the expected path pattern for previous runs\n",
    "# runs/segment/PROJECT_NAME/RUN_NAME* (glob pattern to catch RUN_NAME, RUN_NAME2, etc.)\n",
    "# This is important because if RUN_NAME is reused, Ultralytics appends numbers to avoid overwriting,\n",
    "# unless 'exist_ok=True' is used in training.\n",
    "# We want to find the *latest* such run if multiple exist.\n",
    "potential_run_dirs_pattern = os.path.join(ULTRALYTICS_RUNS_DIR, SEGMENTATION_TASK_DIR, PROJECT_NAME, RUN_NAME + '*')\n",
    "print(f\"Searching for existing run directories matching pattern: {potential_run_dirs_pattern}\")\n",
    "\n",
    "list_of_potential_run_dirs = sorted(glob.glob(potential_run_dirs_pattern))\n",
    "\n",
    "path_to_existing_best_pt = None\n",
    "if list_of_potential_run_dirs:\n",
    "    latest_run_dir = list_of_potential_run_dirs[-1] # Get the alphabetically last one, usually the latest\n",
    "    print(f\"Found potential latest run directory: {latest_run_dir}\")\n",
    "    \n",
    "    candidate_best_pt_path = os.path.join(latest_run_dir, 'weights', 'best.pt')\n",
    "    if os.path.exists(candidate_best_pt_path):\n",
    "        path_to_existing_best_pt = candidate_best_pt_path\n",
    "        print(f\"Found existing 'best.pt' in the latest run: {path_to_existing_best_pt}\")\n",
    "    else:\n",
    "        print(f\"'best.pt' not found in weights directory of: {latest_run_dir}\")\n",
    "        # Optionally, could check for 'last.pt' as a fallback\n",
    "        # candidate_last_pt_path = os.path.join(latest_run_dir, 'weights', 'last.pt')\n",
    "        # if os.path.exists(candidate_last_pt_path):\n",
    "        #     path_to_existing_best_pt = candidate_last_pt_path # Using last.pt as fallback\n",
    "        #     print(f\"Found existing 'last.pt' as fallback: {path_to_existing_best_pt}\")\n",
    "elif os.path.isfile(model_weights_to_load) and model_weights_to_load.endswith(\".pt\"):\n",
    "    print(f\"Using specified model weights file directly: {model_weights_to_load}\")\n",
    "    path_to_existing_best_pt = model_weights_to_load\n",
    "else:\n",
    "    print(f\"No existing run directories found matching the pattern for PROJECT_NAME='{PROJECT_NAME}' and RUN_NAME='{RUN_NAME}'.\")\n",
    "\n",
    "if path_to_existing_best_pt:\n",
    "    model_weights_to_load = path_to_existing_best_pt\n",
    "    print(f\"Decision: Will start training FROM or RESUME using: {model_weights_to_load}\")\n",
    "else:\n",
    "    print(f\"Decision: No suitable existing 'best.pt' (or 'last.pt') found.\")\n",
    "    print(f\"           Will start training from base official pretrained model: {BASE_PRETRAINED_MODEL_NAME}\")\n",
    "\n",
    "# PRETRAINED_ARG_FOR_TRAIN should be True if we are loading any weights,\n",
    "# be it the base model or a custom best.pt/last.pt.\n",
    "# The YOLO() constructor handles loading the weights specified in model_weights_to_load.\n",
    "# The model.train(pretrained=True) then uses these loaded weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intalize YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initializing YOLO Model ---\n",
      "Loading model with weights from: C:\\Users\\weiss\\Desktop\\JT101\\Models\\larvae_best.pt\n",
      "Successfully initialized YOLO model.\n",
      "Model loaded with official pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Initializing YOLO Model ---\")\n",
    "print(f\"Loading model with weights from: {model_weights_to_load}\")\n",
    "\n",
    "try:\n",
    "    model = YOLO(model_weights_to_load)\n",
    "    print(f\"Successfully initialized YOLO model.\")\n",
    "    if model_weights_to_load == BASE_PRETRAINED_MODEL_NAME:\n",
    "        print(\"Model loaded with official pretrained weights.\")\n",
    "    else:\n",
    "        print(\"Model loaded with custom weights from a previous training run (best.pt or last.pt).\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to initialize YOLO model with weights from {model_weights_to_load}.\")\n",
    "    print(f\"Error details: {e}\")\n",
    "    model = None # Ensure model is None if loading failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting YOLOv8 Segmentation Training ---\n",
      "  Dataset YAML: C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\\dataset.yaml\n",
      "  Model being trained: Initialized from C:\\Users\\weiss\\Desktop\\JT101\\Models\\larvae_best.pt\n",
      "  Epochs: 10\n",
      "  Image Size: 640x640\n",
      "  Batch Size: 8\n",
      "  Device: 0\n",
      "  Project Directory: Larvae_fresh_training\n",
      "  Run Name: train_l_Larvae_seg\n",
      "  Patience for Early Stopping: 10\n",
      "  Number of Data Loader Workers: 4\n",
      "  Using pretrained weights for training (model.train pretrained=True): True\n",
      "  Allow overwrite if run exists (exist_ok=True): True\n",
      "New https://pypi.org/project/ultralytics/8.3.179 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.137  Python-3.9.21 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24575MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\\dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\weiss\\Desktop\\JT101\\Models\\larvae_best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_l_Larvae_seg, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Larvae_fresh_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=Larvae_fresh_training\\train_l_Larvae_seg, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 191 layers, 27,240,227 parameters, 27,240,211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 100.315.7 MB/s, size: 7.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\\labels.cache... 299 images, 0 backgrounds, 0 corrupt: 100%|██████████| 299/299 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 98.022.3 MB/s, size: 7.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\weiss\\Downloads\\larvae_yolo_dataset\\larvae_yolo_dataset\\labels.cache... 299 images, 0 backgrounds, 0 corrupt: 100%|██████████| 299/299 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to Larvae_fresh_training\\train_l_Larvae_seg\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mLarvae_fresh_training\\train_l_Larvae_seg\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/38 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: An error occurred during model training.\n",
      "Error details: DataLoader worker (pid(s) 21144, 19112, 22388, 24224) exited unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if model and data_config: # Proceed only if model is loaded and data_config is available\n",
    "    print(f\"\\n--- Starting YOLOv8 Segmentation Training ---\")\n",
    "    print(f\"  Dataset YAML: {DATASET_YAML_PATH}\")\n",
    "    print(f\"  Model being trained: Initialized from {model_weights_to_load}\")\n",
    "    print(f\"  Epochs: {EPOCHS}\")\n",
    "    print(f\"  Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "    print(f\"  Batch Size: {BATCH_SIZE if BATCH_SIZE!= -1 else 'Auto (approx. 60% GPU Mem)'}\")\n",
    "    print(f\"  Device: {DEVICE if DEVICE is not None else 'Auto (GPU if available, else CPU)'}\")\n",
    "    print(f\"  Project Directory: {PROJECT_NAME}\")\n",
    "    print(f\"  Run Name: {RUN_NAME}\")\n",
    "    print(f\"  Patience for Early Stopping: {PATIENCE}\")\n",
    "    print(f\"  Number of Data Loader Workers: {WORKERS}\")\n",
    "    print(f\"  Using pretrained weights for training (model.train pretrained={PRETRAINED_ARG_FOR_TRAIN}): {PRETRAINED_ARG_FOR_TRAIN}\")\n",
    "    print(f\"  Allow overwrite if run exists (exist_ok=True): True\") # Set based on desired behavior\n",
    "\n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=DATASET_YAML_PATH,\n",
    "            epochs=EPOCHS,\n",
    "            imgsz=IMAGE_SIZE,\n",
    "            batch=BATCH_SIZE,\n",
    "            device=DEVICE,\n",
    "            project=PROJECT_NAME,\n",
    "            name=RUN_NAME,\n",
    "            exist_ok=True,  # If True, overwrites the existing 'RUN_NAME' directory if it exists.\n",
    "                            # Set to False if each execution should create a new numbered run (e.g., RUN_NAME2).\n",
    "                            # For the logic of finding and continuing from best.pt of a specific RUN_NAME,\n",
    "                            # exist_ok=True is generally suitable if you intend to refine that *exact* run.\n",
    "                            # If RUN_NAME is a generic name and you expect multiple iterations,\n",
    "                            # the globbing logic handles finding the latest.\n",
    "            patience=PATIENCE,\n",
    "            workers=WORKERS,\n",
    "            pretrained=PRETRAINED_ARG_FOR_TRAIN # This ensures that the weights loaded into the 'model' object\n",
    "                                               # (either base pretrained or custom best.pt) are used as the\n",
    "                                               # starting point for this training session. [12, 13]\n",
    "        )\n",
    "        print(\"\\n--- Training Complete ---\")\n",
    "        print(f\"Training results and artifacts saved in: {os.path.join(ULTRALYTICS_RUNS_DIR, SEGMENTATION_TASK_DIR, PROJECT_NAME, model.trainer.save_dir.name)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An error occurred during model training.\")\n",
    "        print(f\"Error details: {e}\")\n",
    "else:\n",
    "    if not model:\n",
    "        print(\"\\nSkipping training because the model was not loaded successfully.\")\n",
    "    if not data_config:\n",
    "        print(\"\\nSkipping training because the dataset configuration (data.yaml) was not loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Trained Model (Optional / not helpful, use compareModels.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading the Best Trained Model for Inference ---\n",
      "Located best model from the recent training session: Larvae_additional_training\\train_l_Larvae_seg\\weights\\best.pt\n",
      "Loading best performing model from: Larvae_additional_training\\train_l_Larvae_seg\\weights\\best.pt\n",
      "Successfully loaded the trained model.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Loading the Best Trained Model for Inference ---\")\n",
    "\n",
    "# The training process saves the run in a directory that might be RUN_NAME or RUN_NAME<number>.\n",
    "# We need to find the actual save directory used by the trainer.\n",
    "# If model.train() completed successfully, model.trainer.save_dir should point to the correct run directory.\n",
    "\n",
    "final_best_model_path = None\n",
    "actual_run_save_dir = None\n",
    "\n",
    "if 'results' in locals() and hasattr(results, 'save_dir'): # 'results' is the output of model.train()\n",
    "    actual_run_save_dir = results.save_dir # This is the most reliable path if training just completed\n",
    "    candidate_final_best_pt = os.path.join(actual_run_save_dir, 'weights', 'best.pt')\n",
    "    if os.path.exists(candidate_final_best_pt):\n",
    "        final_best_model_path = candidate_final_best_pt\n",
    "        print(f\"Located best model from the recent training session: {final_best_model_path}\")\n",
    "    else:\n",
    "        print(f\"WARNING: 'best.pt' not found in the expected training output directory: {os.path.join(actual_run_save_dir, 'weights')}\")\n",
    "        # Fallback: try to glob again, in case 'results' object is not available or run was from a previous session\n",
    "        potential_run_dirs_after_train_pattern = os.path.join(ULTRALYTICS_RUNS_DIR, SEGMENTATION_TASK_DIR, PROJECT_NAME, RUN_NAME + '*')\n",
    "        list_of_potential_run_dirs_after_train = sorted(glob.glob(potential_run_dirs_after_train_pattern))\n",
    "        if list_of_potential_run_dirs_after_train:\n",
    "            latest_run_dir_after_train = list_of_potential_run_dirs_after_train[-1]\n",
    "            candidate_final_best_pt_glob = os.path.join(latest_run_dir_after_train, 'weights', 'best.pt')\n",
    "            if os.path.exists(candidate_final_best_pt_glob):\n",
    "                final_best_model_path = candidate_final_best_pt_glob\n",
    "                print(f\"Located best model via globbing: {final_best_model_path}\")\n",
    "            else:\n",
    "                 print(f\"WARNING: 'best.pt' also not found via globbing in {latest_run_dir_after_train}/weights/\")\n",
    "elif model and hasattr(model, 'trainer') and model.trainer and hasattr(model.trainer, 'save_dir'):\n",
    "    # Alternative if 'results' is not available but 'model' object from training is\n",
    "    actual_run_save_dir = model.trainer.save_dir\n",
    "    candidate_final_best_pt = os.path.join(actual_run_save_dir, 'weights', 'best.pt')\n",
    "    if os.path.exists(candidate_final_best_pt):\n",
    "        final_best_model_path = candidate_final_best_pt\n",
    "        print(f\"Located best model from model.trainer.save_dir: {final_best_model_path}\")\n",
    "\n",
    "\n",
    "if final_best_model_path:\n",
    "    print(f\"Loading best performing model from: {final_best_model_path}\")\n",
    "    try:\n",
    "        trained_model = YOLO(final_best_model_path)\n",
    "        print(\"Successfully loaded the trained model.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load the trained model from {final_best_model_path}. Error: {e}\")\n",
    "        trained_model = None\n",
    "else:\n",
    "    print(f\"CRITICAL WARNING: Could not find 'best.pt' from the training run. Please check the path: \"\n",
    "          f\"{os.path.join(ULTRALYTICS_RUNS_DIR, SEGMENTATION_TASK_DIR, PROJECT_NAME, RUN_NAME, 'weights', 'best.pt')} \"\n",
    "          f\"or similar if RUN_NAME was suffixed.\")\n",
    "    print(\"Prediction cannot proceed without a loaded model.\")\n",
    "    trained_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_seg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
